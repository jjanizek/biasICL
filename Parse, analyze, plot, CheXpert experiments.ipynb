{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51eeb84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import ast\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ba5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"chexpertBinaryPNA_0_0_0_0_gpt-4o-2024-05-13_50.pkl\", \"rb\") as f:\n",
    "    raw_pickle = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3037134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m raw_pickle\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "for k,v in raw_pickle.items():\n",
    "    print(len(v[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12f8d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_to_res(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        raw_pickle = pickle.load(f)\n",
    "\n",
    "    results = {}\n",
    "    answer_prefix=\"Answer Choice \"\n",
    "\n",
    "    def extract_ans(ans_str, search_substring):\n",
    "        # Split the string into lines\n",
    "        lines = ans_str.split(\"\\n\")\n",
    "\n",
    "        for line in lines:\n",
    "            # Check if the line starts with the specified substring\n",
    "            if line.startswith(search_substring):\n",
    "                # If it does, add it to the list of extracted rows\n",
    "                return line[len(search_substring) :].strip()\n",
    "        return \"ERROR\"  # Answer not found\n",
    "\n",
    "    for k, v in raw_pickle.items():\n",
    "        if k != 'token_usage':  # Skip token_usage\n",
    "            qns_idx = ast.literal_eval(k)\n",
    "            for idx, qn_idx in enumerate(qns_idx):\n",
    "                results[qn_idx] = extract_ans(\n",
    "                    v[0], f\"{answer_prefix}{idx+1}:\"\n",
    "                )  # We start with question 1\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d89d12bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_to_vec(res):\n",
    "    test_df = pd.read_csv('/home/joseph/datasets/chexpertchestxrays-u20210408/chexpert_binaryPNA_test_df_labels.csv', index_col=0)\n",
    "    num_errors = 0\n",
    "    labels, preds, race = [], [], []\n",
    "    for i in test_df.itertuples():\n",
    "        if (i.Index not in results) or (results[i.Index].startswith(\"ERROR\")):\n",
    "            num_errors += 1\n",
    "\n",
    "            print(i.Index, f\"answer not found\")\n",
    "            continue\n",
    "\n",
    "        pred_text = results[i.Index]\n",
    "        ground_truth = \"B\" if i.Pneumonia == 1 else \"A\"\n",
    "        labels.append(ground_truth)\n",
    "        preds.append(pred_text)\n",
    "        race.append(i.binary_race)\n",
    "        \n",
    "    print(f\"In total {num_errors} errors len = {len(labels)}\")\n",
    "    return labels,preds,race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9caa6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(actual, predicted):\n",
    "    TP = sum((a == 'B' and p == 'B') for a, p in zip(actual, predicted))\n",
    "    TN = sum((a == 'A' and p == 'A') for a, p in zip(actual, predicted))\n",
    "    FP = sum((a == 'A' and p == 'B') for a, p in zip(actual, predicted))\n",
    "    FN = sum((a == 'B' and p == 'A') for a, p in zip(actual, predicted))\n",
    "    \n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    if precision + recall > 0:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1_score = 0\n",
    "    \n",
    "    accuracy = (TP + TN) / len(actual)\n",
    "    tpr = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    tnr = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    \n",
    "    return accuracy, tpr, tnr, f1_score\n",
    "\n",
    "\n",
    "\n",
    "def filter_by_race(actual, predicted, race, race_value):\n",
    "    filtered_actual = [a for a, r in zip(actual, race) if r == race_value]\n",
    "    filtered_predicted = [p for p, r in zip(predicted, race) if r == race_value]\n",
    "    return filtered_actual, filtered_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d114e69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total 0 errors len = 600\n"
     ]
    }
   ],
   "source": [
    "results = pickle_to_res(\"chexpertBinaryPNA_0_0_0_0_gpt-4o-2024-05-13_50.pkl\")\n",
    "labels,preds,race = res_to_vec(results)\n",
    "accuracy, tpr, tnr, fscore = calculate_metrics(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9461759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45166666666666666, 0.74, 0.16333333333333333, 0.574385510996119)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy, tpr, tnr, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b77935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for race white\n",
    "actual_white, predicted_white = filter_by_race(labels, preds, race, 'White')\n",
    "accuracy_white, tpr_white, tnr_white, fscore_white = calculate_metrics(actual_white, predicted_white)\n",
    "\n",
    "# Filter for race black\n",
    "actual_black, predicted_black = filter_by_race(labels, preds, race, 'Black')\n",
    "accuracy_black, tpr_black, tnr_black, fscore_black = calculate_metrics(actual_black, predicted_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5522a488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45, 0.4533333333333333)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_black,accuracy_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b927ef76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (biasenv)",
   "language": "python",
   "name": "biasenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
